<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="What is reasoning?">
  <meta property="og:title" content="What is reasoning?"/>
  <meta property="og:description" content="What is reasoning?"/>
  <meta property="og:url" content="https://jmaasch.github.io/carc/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/pch.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600
  <meta name="twitter:title" content="What is reasoning?">
  <meta name="twitter:description" content="What is reasoning?">
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
-->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="reasoning, language models, large language models, large reasoning models, generative ai, ai evaluation, logic, epistemology, construct validity">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>What is reasoning?</title>
  <link rel="icon" type="image/x-icon" href="static/images/brain.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <script type="text/javascript"
  src="https://www.maths.nottingham.ac.uk/plp/pmadw/LaTeXMathML.js">
  </script>

  <!-- SITE ICON -->
  <link rel="icon"
  type="image/png"
  href="static/images/brain_icon.png">
</head>
<body>


<section class="hero">
  <div class="hero-body">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths is-centered has-text-centered">

        <!-- TITLE -->

        <p style="text-align:center">
          <img style="vertical-align:middle" src='static/images/rainbow_medium_3.png' width="100%" class="center">
        </p>
        <br>
        <br>

        <h1 class="title is-1 publication-title">What is reasoning?</h1>

        <p style="text-align:center">
          <img style="vertical-align:middle" src='static/images/brain_crop.png' width="20%" class="center">
        </p>
        <br>
        <br>

        <!-- AUTHORS -->

        <p style="text-align:center">
          <img style="vertical-align:middle" src='static/images/rainbow_xsmall_1.png' width="100%" class="center">
        </p>
        <br>

        This site is based on the paper:
        <br>

        <b>Position: Beyond <i>Reasoning Zombies</i> — AI Reasoning Requires Process Validity</b>
        <br>
        <a href="https://rlaw.me/" target="_blank">Rachel Lawrence</a><sup>1*</sup> &nbsp;&nbsp;&nbsp; <a href="https://jmaasch.github.io/" target="_blank">Jacqueline Maasch</a><sup>2*</sup>
        <br>
        <sup>*</sup>Equal contribution &nbsp;&nbsp;&nbsp; <sup>1</sup>Microsoft Research, Cambridge, UK &nbsp;&nbsp;&nbsp; <sup>2</sup>Cornell Tech, New York, NY
        <br>
        <br>

        <!-- ArXiv abstract Link
        <span class="link-block">
          <a href="static/pdfs/position.pdf" target="_blank"
          class="external-link button is-normal is-rounded is-light">
          <span class="icon">
            <i class="ai ai-arxiv"></i>
          </span>
          <span>arXiv</span>
        </a>
        </span>
         -->

        <!-- Paper PDF Link -->
        <span class="link-block">
          <a href="static/pdfs/position.pdf" target="_blank"
          class="external-link button is-normal is-rounded is-light">
          <span class="icon">
            <i class="fas fa-file-pdf"></i>
          </span>
          <span>Paper</span>
        </a>
        </span>

        <!-- Github link -->
        <span class="link-block">
          <a href="https://github.com/jmaasch/valid_reasoning" target="_blank"
          class="external-link button is-normal is-rounded is-light">
          <span class="icon">
            <i class="fab fa-github"></i>
          </span>
          <span>Code</span>
        </a>
        </span>

        <br>
        <br>

        <p style="text-align:center">
          <img style="vertical-align:middle" src='static/images/rainbow_xsmall_4.png' width="100%" class="center">
        </p>

        <div class="content has-text-justified">

          <br>
          <br>

          <!-- DEFINITIONS -->

          <div class="column has-text-centered">

            <h2 class="title">Background.</h2>

          </div>


          Defining <i>reasoning</i> is a nontrivial task. Over millenia, many definitions have been proposed in philosophy, mathematics, cognitive science, and computing. In contemporary AI, it can be challenging to identify authoritative <i>operational</i> definitions that are simultaneously compatible with symbolic, neural, and neuro-symbolic methods. 
          <br>
          <br>

          Based on a synthesis of the literature, we provide an operational definition for reasoning as a learnable, rule-governed process. This definition is intended for general use and community discussion. We express this definition in natural language for intuition, mathematical notation for concretization, and pseudocode. See our <a href="static/pdfs/position.pdf" target="_blank">full paper</a> for further discussion. Our core theses are summarized below.
          <br>
          <br>

          <details>
            <summary><b>Core theses.</b></summary>
            <ol>
              <li><b>Define, then measure.</b> Research concerned with AI reasoning should provide formal <i>operational</i> definitions for the reasoning phenomena under investigation. The <i>construct validity</i> of reasoning evaluation should be explicitly justified with respect to the operational definitions provided.</li>
              <li><b>Reasoning is a (learnable) rule-based process.</b> Reasoning is a process of exact rule application. Learnable rules unambiguously map reasoning inputs to outputs and can encompass theorems, functions, policies, etc., including rules pertaining to stochasticity, uncertainty, and approximation.</li>
              <li><b>Rule-based reasoning is valid.</b> The validity of a reasoning process arises from exact rule application, independent of rule selection.</li>
            </ol>  
          </details>

          <br>
          <br>
          <br>

          <p style="text-align:center">
            <img style="vertical-align:middle" src='static/images/rainbow_xsmall_1.png' width="100%" class="center">
          </p>

          <br>
          <br>

          <div class="column has-text-centered">

            <h2 class="title">Reasoning is a (learnable) rule-based process.</h2>

          </div>



          First, we begin with definitions in plain English for intuition.
          <br>
          <br>

          <div class="box">
            <b>Definition 1 (Reasoning, informal).</b> The process of selecting and applying sequences of rules that act on prior beliefs and current evidence to obtain principled belief updates in evolving states.
          </div>

          <div class="box">
            <b>Definition 2 (Reasoner, informal).</b> A goal-oriented decision-maker that implements reasoning.
          </div>

          <br>
          Note that <b>rules are both learnable and defeasible</b> in the general case, rendering Definition 1 compatible with the bitter lesson and machine learning (<a href="https://heartyhaven.github.io/files/bitter_lesson.pdf" target="_blank">Sutton 2019</a>). In special cases, rules may be hard-coded by experts (as in some symbolic methods). Read more about each core component of Definitions 1 and 2 by expanding the terms below.

          <br>
          <br>

          <details>
            <summary><b>Process.</b></summary>
            Reasoning is a dynamic process, not an output. Thus, reasoning entails $T \geq 1$ hops, stages, time steps, or <i>reasoning steps</i>. This process implies a design component: sequences of rules or actions are chosen by the reasoner according to some justification. The process of <i>selection</i> is where agency, intelligence, or creativity may come into play, while the process of <i>execution</i> necessitates exactness and rigor. Note that it may be perfectly reasonable for the selection criterion to be random selection.
            <br>
            <br>
            We echo <a href="https://arxiv.org/abs/1911.01547" target="_blank">Chollet (2019)</a> on the risks of "confusing the process of intelligence" (reasoning, in our case) "with the artifact produced by this process" (e.g., QA responses), ignoring the generating mechanism: "In the case of AI, the focus on achieving task-specific performance while placing no conditions on <i>how the system arrives at this performance</i> has led to systems that, despite performing the target tasks well, <i>largely do not feature the sort of human intelligence that the field of AI set out to build</i>" (original emphasis). <a href="https://link.springer.com/article/10.1007/bf02512227" target="_blank">Simon (2000)</a> similarly argued that a theory of bounded rationality "will be as much concerned with [...] the quality of the processes of decision, as with [...] the quality of the outcome."
            <br>
            <br>
          </details>

          <details>
            <summary><b>Goal.</b></summary>
            The reasoner generally executes a reasoning process to achieve some outcome of interest. This outcome is the <i>goal</i> one is reasoning toward: the answer to a complex question, the solution to a puzzle, the shortest path through a maze, a mathematical proof, the optimal action to take under resource constraints, etc. In distinguishing the goal-directed reasoner from the reasoning process itself, we highlight that the <i>validity</i> of the reasoning process is not necessarily tied to successful attainment of a goal. In practice, we can encode the goal in a stopping rule, where reasoning terminates when the rule is satisfied. We do not restrict our notion of goals to the formal sense used in RL, though it is compatible with this interpretation.
            <br>
            <br>
          </details>

          <details>
            <summary><b>Rules.</b></summary>
            Collectively, the rule set unambiguously maps the reasoning state at $t$ to the state at $t+1$. In general, rules are selected with some justification prior to deployment. Rules can take the form of algorithms, formulae, theorems, axioms, laws, policies, premises, assumptions, decision boundaries, etc. Rules can be extrinsically imposed on the reasoner (i.e., hard-coded by another individual or collective agent, such as a human or government) or they can be learned autonomously from data on-the-fly. Rules can be fixed or continuously updated in light of new information.
            <br>
            <br>
            Note that rule-governed reasoning and data-driven models are not mutually exclusive, and we reject the false dichotomy between rule-based symbolic AI and contemporary probabilistic deep learning. <i>Learnable rules</i> are essential for tying Definition 1 to modern AI and the bitter lesson (<a href="https://heartyhaven.github.io/files/bitter_lesson.pdf" target="_blank">Sutton 2019</a>): rules do not need to be hard-coded by human domain experts, and the future of autonomous reasoning will likely include systems that learn defeasible rules and beliefs on-the-fly.
            <br>
            <br>
          </details>

          <details>
            <summary><b>Evidence.</b></summary>
            Evidence is a form of exogenous or extrinsically obtained information. We model evidence as a continuous stream of data that is updated at each step $t$ or at intervals. <i>Current evidence</i> denotes information presented at $t$, along with the historical record: aggregated information up to $k \geq 0$ steps prior to $t$. Evidence may be gained directly through sequential interactions with an uncertain environment (as in online RL, field work in the natural sciences, etc.) or provided without direct collection (e.g., retrospective data collected by another agent). In trivial cases, external evidence is the empty set or is provided at $t=0$ and never updated.
            <br>
            <br>
          </details>

          <details>
            <summary><b>Prior beliefs.</b></summary>
            While evidence is a form of exogenous or extrinsically obtained information, we model  beliefs as a form of endogenous or intrinsically obtained information. <i>Prior beliefs</i> are the outputs of previous reasoning steps, up to step $t-k$ for $t > k \geq 1$. They can be viewed as intermediate conclusions along the reasoning pathway that led to step $t$. Often, they are defeasible: they can be overwritten if proven false (e.g., in backtracking proof search), refined if insufficient, or maintained and aggregated with current beliefs at step $t$. They can also be  provided at $t=0$ (e.g., initializing Bayesian priors based on convention when supporting evidence is not yet available). 
            <br>
            <br>
          </details>

          <details>
            <summary><b>Current beliefs.</b></summary>
            Current beliefs denote the conclusions drawn in the transition from $t-1$ to $t$. When $t=T$, current belief is equivalent to the <i>terminal conclusion</i> of the reasoning process. The nature of the terminal conclusion is a defining property of the type of reasoning performed, e.g.: the output of a function in mathematical reasoning, an optimal action in practical reasoning, a moral verdict in moral reasoning, a judiciary decision in legal reasoning, etc. 
            <br>
            <br>
          </details>

          <details>
            <summary><b>Evolving states.</b></summary>
            A reasoner will generally maintain an <i>internal representation</i> of its world state, which updates over time. The existence of an <i>external environment</i> is also implied by our choice to model evidence as a stream of extrinsic signals. However, we note that a well-defined concept of external environment is not relevant in all cases (e.g., in some mathematical reasoning domains). Thus, we place no requirements on the existence or direct observability of an external environment, physical world, etc., and only require an internal representation of the world (i.e., the state). We use the notion of an <i>evolving state</i> broadly to encode all of the above concepts: (1) dynamically updated internal state representations, (2) changing and/or uncertain external worlds, and (3) extrinsic sources of evidence. 
            <br>
            <br>
          </details>

          <br>

          Finally, we provide our (abbreviated) formal definitions for <i>valid</i> and <i>sound reasoning</i>. For complete formal definitions and pseudocode, see our <a href="static/pdfs/position.pdf" target="_blank">full paper</a>.

          <br>
          <br>

          <div class="box">
            <b>Definition 3 (Reasoning, formal).</b> Let ${S}_t := \langle {B}_t, {E}_t, {R}_t \rangle$ denote the reasoner's state at time step $t$, where ${B}_t$ denotes current belief, ${E}_t$ denotes aggregated evidence up to time $t$, and ${R}_t$ denotes the current set of established rules. Then, <i>reasoning</i> is the iterated application over steps $t$ of rules $r \in {R}_{t-1}$ to prior beliefs ${B}_{t-1}$ and current evidence ${E}_{t}$, by which we obtain dynamically updated states ${S}_t$, and where every output ${B}_{t}$ for $t>0$ is the result of a rule application $r({B}_{t-1}, {E}_{t})$ to the contents of state ${S}_{t-1}$.
          </div>

          <div class="box">
            <b>Definition 4 (Validity).</b> A transition from state ${S}_t$ to ${S}_{t+1}$ is <i>valid</i> if and only if it arises from the application of a rule $r \in {R}_t$ to components of state ${S}_t$.
          </div>

          <div class="box">
            <b>Definition 5 (Soundness).</b> A valid transition from state ${S}_t$ to ${S}_{t+1}$ is <i>sound</i> if and only if all premises (as encoded by beliefs, rules, and evidence) are true with respect to external evaluation. 
          </div>

          <br>
          We introduce the concept of <i>reasoning zombies</i> to differentiate valid reasoning from superficial <i>reasoning emulation</i> (e.g., <i>talking like a reasoner</i> with no guarantees that conclusions arose from reasoning rather than memorization, guessing, or some other behavior). This concept is a rough analogue of the classic <i>philosophical zombie</i> (<i>p</i>-zombie) thought experiment (<a href="https://philpapers.org/rec/JCHTCM-2" target="_blank">Chalmers 1997</a>).

          <br>
          <br>

          <div class="box">
            <b>Definition 6 (Reasoning zombie, informal).</b> A reasoning zombie (<i>r</i>-zombie) is a system that superficially behaves as an autonomous reasoner, but lacks the internal mechanisms necessary for validity.
          </div>

          <!-- BIBTEX -->

          <br>
          <br>
          <br>

          <p style="text-align:center">
            <img style="vertical-align:middle" src='static/images/rainbow_xsmall_3.png' width="100%" class="center">
          </p>

          <br>
          <br>

          <div class="column has-text-centered">

            <h2 class="title">How to cite this work.</h2>

          </div>

          Please cite our work using the following BibTeX.<br><br>
<!-- due to the pre-formatted tag, this block must not be indented. -->
<pre><code>@misc{lawrence2026reasoning,
  title={Position: Beyond Reasoning Zombies — AI Reasoning Requires Process Validity},
  author={Lawrence, Rachel and Maasch, Jacqueline},
  url={https://jmaasch.github.io/reasoning/position.pdf}
}
</code></pre>

          <br>

          <p style="text-align:center">
            <img style="vertical-align:middle" src='static/images/rainbow_medium_1.png' width="100%" class="center">
          </p>

        </div>
      </div>
    </div>
  </div>
</div>
</section>




<!--BibTex citation 
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title" id="bibtex">How to cite this work</h2>
      Please cite our work using the following BibTeX.<br><br>
      <pre><code>
      @misc{lawrence2026reasoning,
        title={Position: Beyond Reasoning Zombies — AI Reasoning Requires Process Validity},
        author={Lawrence, Rachel and Maasch, Jacqueline},
        url={https://jmaasch.github.io/reasoning/static/pdfs/position.pdf}
      }
      </code></pre>
    </div>
</section>
-->


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>
